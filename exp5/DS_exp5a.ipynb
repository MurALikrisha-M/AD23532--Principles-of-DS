{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iat6_Pz56Gr3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DrbxFz_6O3f"
      },
      "source": [
        "Import NLTK Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ7xacLb6J0G",
        "outputId": "e11c1001-09d7-40f8-9bf2-6ceb9b0e23dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download(\"maxent_ne_chunker_tab\")\n",
        "nltk.download(\"words\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ne_chunk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t83awa_I6rE9"
      },
      "source": [
        "Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yCPnyrV6tfu"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Reviews.csv\", on_bad_lines=\"skip\", engine=\"python\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SdH7HMw6yzO"
      },
      "outputs": [],
      "source": [
        "reviews = df['Text']\n",
        "reviews = reviews.dropna()\n",
        "reviews = reviews.head(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUW2IHrE65uf"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBZ9jfCr66Id"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
        "    return text\n",
        "\n",
        "reviews = reviews.apply(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WamX2LhP6_xt"
      },
      "source": [
        "Tokenization + clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rimMcZVR7BVW"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def tokenize_and_clean(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w for w in tokens if w.isalpha()]  # only words\n",
        "    tokens = [w for w in tokens if w not in stop_words]  # remove stopwords\n",
        "    return tokens\n",
        "\n",
        "tokens_list = reviews.apply(tokenize_and_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8KmKTF87EWl"
      },
      "source": [
        "POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY-KPmAF7F8d"
      },
      "outputs": [],
      "source": [
        "pos_tagged = tokens_list.apply(pos_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rng0iim37Int"
      },
      "source": [
        " Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yzfjGfXq7KB1"
      },
      "outputs": [],
      "source": [
        "ner_results = pos_tagged.apply(ne_chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXR_XcWG7OQV"
      },
      "source": [
        "Example Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2iECuYjx7OrN",
        "outputId": "82dcac05-b903-4d11-d2df-9bb075ad7bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Review: i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most\n",
            "\n",
            "Tokens: ['bought', 'several', 'vitality', 'canned', 'dog', 'food', 'products', 'found', 'good', 'quality', 'product', 'looks', 'like', 'stew', 'processed', 'meat', 'smells', 'better', 'labrador', 'finicky', 'appreciates', 'product', 'better']\n",
            "\n",
            "POS Tags: [('bought', 'VBD'), ('several', 'JJ'), ('vitality', 'NN'), ('canned', 'VBD'), ('dog', 'JJ'), ('food', 'NN'), ('products', 'NNS'), ('found', 'VBD'), ('good', 'JJ'), ('quality', 'NN'), ('product', 'NN'), ('looks', 'VBZ'), ('like', 'IN'), ('stew', 'NN'), ('processed', 'VBN'), ('meat', 'NN'), ('smells', 'NNS'), ('better', 'RBR'), ('labrador', 'NN'), ('finicky', 'JJ'), ('appreciates', 'VBZ'), ('product', 'NN'), ('better', 'RBR')]\n",
            "\n",
            "NER Tree: (S\n",
            "  bought/VBD\n",
            "  several/JJ\n",
            "  vitality/NN\n",
            "  canned/VBD\n",
            "  dog/JJ\n",
            "  food/NN\n",
            "  products/NNS\n",
            "  found/VBD\n",
            "  good/JJ\n",
            "  quality/NN\n",
            "  product/NN\n",
            "  looks/VBZ\n",
            "  like/IN\n",
            "  stew/NN\n",
            "  processed/VBN\n",
            "  meat/NN\n",
            "  smells/NNS\n",
            "  better/RBR\n",
            "  labrador/NN\n",
            "  finicky/JJ\n",
            "  appreciates/VBZ\n",
            "  product/NN\n",
            "  better/RBR)\n"
          ]
        }
      ],
      "source": [
        "print(\"Sample Review:\", reviews.iloc[0])\n",
        "print(\"\\nTokens:\", tokens_list.iloc[0])\n",
        "print(\"\\nPOS Tags:\", pos_tagged.iloc[0])\n",
        "print(\"\\nNER Tree:\", ner_results.iloc[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
